{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한거 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (4.21.1)\n",
      "Requirement already satisfied: torch in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (1.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (2022.7.25)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: requests in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Collecting git+https://github.com/facebookresearch/esm.git\n",
      "  Cloning https://github.com/facebookresearch/esm.git to /tmp/pip-req-build-pj2wax1y\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/esm.git /tmp/pip-req-build-pj2wax1y\n",
      "  Resolved https://github.com/facebookresearch/esm.git to commit 723e85829b1c175f23d9c1195b0fb47d6b2bf5cd\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "!pip install git+https://github.com/facebookresearch/esm.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한거 import하고 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertConfig, BertTokenizer\n",
    "from esm.data import ESMStructuralSplitDataset\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "esm_structural_train = ESMStructuralSplitDataset(\n",
    "    split_level='superfamily', \n",
    "    cv_partition='4', \n",
    "    split='train', \n",
    "    root_path = os.path.expanduser('~/.cache/torch/data/esm'),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretraining을 이 데이터로만 하면 의미가 없습니다! 더 많은 데이터를 가지고 하는게 좋고, 이번에는 예시로서 보여드리기위해 이것으로 합니다.\n",
    "seqs = [data['seq'] for data in esm_structural_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='mytoken', vocab_size=32, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('mytoken')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수, 함수들의 역할 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.21.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_n_label(seq):\n",
    "    seq = list(seq)\n",
    "    seq = np.array(seq, dtype='<U6')\n",
    "    mask1 = np.random.random(size=seq.shape)<0.15\n",
    "    u = np.random.random(size=seq.shape)\n",
    "    mask = mask1 & (u < 0.8)\n",
    "    tokens = list('ABCDEFGHIKLMNOPQRSTUVWXYZ-.')\n",
    "    random_another_mask = mask1 & (u>=0.8) & (u<0.9)\n",
    "    random_another = np.random.choice(tokens, size = seq.shape)\n",
    "    \n",
    "    seqm = seq.copy()\n",
    "    seqm[mask] = '[MASK]'\n",
    "    seqm[random_another_mask] = random_another[random_another_mask]\n",
    "    \n",
    "    seqL = seq.copy()\n",
    "    seqL[~mask] = '[MASK]'\n",
    "    \n",
    "    return ' '.join(seqm), ' '.join(seqL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[MASK] [MASK] T V R Q E R L K S I V R I L E [MASK] S K E P V S G A Q L A E E L S V S R Q [MASK] I V [MASK] [MASK] I A Y L R F L G [MASK] N I V A T P R G H V L A G G',\n",
       " 'M K [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] R [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] V [MASK] [MASK] Q D [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] Y [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_input_n_label(seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [make_input_n_label(seq) for seq in seqs[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [e[0] for e in example]\n",
    "labels = [e[1] for e in example]\n",
    "inputs = tokenizer(inputs, return_tensors='pt', padding=True)\n",
    "labels = tokenizer(labels, return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2, 16, 14, 23,  4,  4, 20,  9, 21, 15,  4,  5, 28, 25, 21,  4, 15,  9,\n",
       "         11, 22, 14,  9, 19, 25, 22, 11,  5, 20, 15,  5,  9,  9, 15,  4,  4, 22,\n",
       "         21, 20, 25,  4, 25,  4,  4, 13,  5, 28, 15, 21, 22, 15,  4, 28,  4, 13,\n",
       "         25,  5, 23,  4, 21,  4, 28, 25, 15,  5, 11, 11,  3,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0],\n",
       "        [ 2, 14,  5, 15, 23,  5, 21, 20, 20,  9, 25,  4, 25,  4, 13, 21,  8, 12,\n",
       "         13, 22, 20, 23, 11, 16, 19, 19, 23, 21,  5,  9, 13,  5, 20, 21, 15, 11,\n",
       "         10, 21, 22, 19, 17,  5,  4,  9,  9,  4, 15, 14,  5, 15,  4, 21, 14, 11,\n",
       "         25,  4,  4, 13, 25, 22, 11,  5, 22, 21, 11, 13,  4, 15, 15, 20,  9,  9,\n",
       "          3,  0,  0,  0,  0],\n",
       "        [ 2, 11, 20, 21,  4,  4, 14,  4, 21,  9,  4, 13, 16,  4, 17,  8, 13,  9,\n",
       "          4, 20,  8,  9, 15,  4,  8, 21, 15, 21,  9,  5, 11,  4, 17, 25, 23, 20,\n",
       "          5, 23, 25, 22, 21,  8, 13, 14,  9, 16,  4, 15, 25, 14, 25, 19,  4,  5,\n",
       "          4,  4, 21, 28, 14, 28,  4, 15, 19, 22,  8, 20, 21, 10, 17,  4,  4,  4,\n",
       "         14, 15, 14, 21,  3],\n",
       "        [ 2, 16, 17, 14, 11, 20, 21, 12, 13, 14, 13, 21,  9, 13, 13, 23, 22, 17,\n",
       "          9, 13,  9, 23, 20,  8,  9, 15, 25,  4, 16, 15, 14,  4,  8, 11, 28, 14,\n",
       "         25, 23, 20,  5, 23, 25,  4, 21,  8, 13,  4,  9,  4,  4, 15,  4, 14, 25,\n",
       "         19, 23, 17, 17, 11, 22, 28, 14, 28, 22, 15,  3,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['input_ids'][labels['input_ids']<5]=-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100, -100, -100,   25,   21, -100, -100, -100, -100,   14, -100,\n",
       "         -100, -100, -100,   13, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100,   22,   25, -100,\n",
       "         -100, -100, -100,   13, -100,   20,    8, -100, -100, -100, -100, -100,\n",
       "         -100, -100,   11, -100,   17, -100, -100, -100, -100,   19, -100,   11,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,   10,\n",
       "         -100,   15, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100,    5, -100, -100,   12, -100, -100,\n",
       "         -100, -100,    5, -100, -100, -100, -100,   13,    9, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100,   21, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100],\n",
       "        [-100, -100, -100, -100,   12,   13, -100,   13, -100, -100,   13, -100,\n",
       "         -100,   22, -100, -100, -100, -100,   23, -100, -100, -100, -100,   25,\n",
       "         -100, -100, -100, -100, -100, -100, -100,   10, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,   20, -100,\n",
       "         -100, -100, -100, -100,   16, -100,   17,   11, -100, -100, -100, -100,\n",
       "           22, -100, -100, -100, -100, -100, -100, -100, -100,   19,   15,   20,\n",
       "         -100, -100, -100, -100, -100],\n",
       "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100,    8, -100, -100, -100,   20, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100,   22, -100, -100, -100,   14, -100,\n",
       "           15,   12, -100,   25, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=tensor(10.6432, grad_fn=<NllLossBackward0>), logits=tensor([[[ 0.0000,  1.2639,  0.6349,  ..., -0.5563, -0.4117,  0.5651],\n",
       "         [ 0.0000, -0.5571,  0.7112,  ...,  0.6025,  0.4129,  0.3255],\n",
       "         [ 0.0000,  0.1445,  0.4176,  ...,  0.4882, -0.2714,  0.5091],\n",
       "         ...,\n",
       "         [ 0.0000,  0.9921,  0.5531,  ...,  0.1027, -0.6658,  0.1879],\n",
       "         [ 0.0000,  0.5340,  1.0160,  ..., -0.7268, -0.5335,  0.1841],\n",
       "         [ 0.0000,  0.2934,  0.7532,  ..., -0.2197,  0.1762,  0.2255]],\n",
       "\n",
       "        [[ 0.0000,  0.2135, -0.0099,  ..., -0.3568, -0.2432,  0.6962],\n",
       "         [ 0.0000,  0.2477,  0.6386,  ..., -0.2720, -0.6797,  0.6723],\n",
       "         [ 0.0000, -0.2421,  0.1027,  ...,  0.0649,  0.1477, -0.0215],\n",
       "         ...,\n",
       "         [ 0.0000,  0.5423,  0.5032,  ...,  0.1286, -0.2271, -0.0660],\n",
       "         [ 0.0000,  0.6523,  0.6089,  ..., -0.1663, -0.1618,  0.4893],\n",
       "         [ 0.0000,  0.3999,  0.3883,  ..., -0.1876, -0.0862,  0.1799]],\n",
       "\n",
       "        [[ 0.0000,  0.1019,  0.7386,  ..., -0.0493, -0.5139,  0.4231],\n",
       "         [ 0.0000,  0.3432,  0.6754,  ...,  0.4538, -0.1758,  0.3186],\n",
       "         [ 0.0000,  0.2338,  0.7111,  ...,  0.2092, -0.0486,  0.3541],\n",
       "         ...,\n",
       "         [ 0.0000, -0.2576,  0.6493,  ..., -0.0244, -0.3482,  0.0388],\n",
       "         [ 0.0000,  0.1948,  0.5713,  ..., -0.7221, -1.2002,  0.1482],\n",
       "         [ 0.0000,  0.1093,  0.8764,  ..., -0.3605,  0.0484, -0.2714]],\n",
       "\n",
       "        [[ 0.0000,  0.3157,  0.5948,  ..., -0.3782,  0.2609,  0.3282],\n",
       "         [ 0.0000, -0.3676,  0.4673,  ...,  0.4540,  0.0811,  0.7409],\n",
       "         [ 0.0000,  0.1700,  0.6270,  ...,  0.2890, -0.3655,  0.2804],\n",
       "         ...,\n",
       "         [ 0.0000,  0.2186,  0.1874,  ...,  0.1306, -0.1990, -0.4821],\n",
       "         [ 0.0000,  0.6957,  0.1816,  ..., -0.4950, -0.3411,  0.4763],\n",
       "         [ 0.0000,  0.1423,  0.2652,  ..., -0.3898, -0.2503,  0.3923]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(**inputs, labels=labels['input_ids'])\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 시작해봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # gpu가 있으면 이것을 'cuda'로 변경하면 됨.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(seqs, batch_size, device):\n",
    "    n = len(seqs)\n",
    "    nb = n//batch_size\n",
    "    for i in range(nb):\n",
    "        example = [make_input_n_label(seq) for seq in seqs[i*batch_size:(i+1)*batch_size]]\n",
    "        inputs = [e[0] for e in example]\n",
    "        labels = [e[1] for e in example]\n",
    "        inputs = tokenizer(inputs, return_tensors='pt', padding=True)\n",
    "        labels = tokenizer(labels, return_tensors='pt', padding=True)\n",
    "        inputs['input_ids'].to(device)\n",
    "        inputs['token_type_ids'].to(device)\n",
    "        inputs['attention_mask'].to(device)\n",
    "        labels['input_ids'][labels['input_ids']<5]=-100\n",
    "        labels['input_ids'].to(device)\n",
    "        yield inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackjack5/program/anaconda3/envs/contact_prediction/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "optim = AdamW(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 10\n",
    "for epoch in range(epochs):\n",
    "    gen = generate_batch(seqs, batch_size, device)\n",
    "    for inputs, labels in gen:\n",
    "        optim.zero_grad()\n",
    "        out = model(**inputs, labels=labels['input_ids'])\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print('loss : ',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('pretrained', exist_ok=True)\n",
    "model.save_pretrained('./pretrained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
